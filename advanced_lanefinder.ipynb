{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FIGURE_SIZE = (12, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "TEST_IMG_OUTPUT_PATH = \"test_images_output\"\n",
    "\n",
    "if not os.path.isdir(TEST_IMG_OUTPUT_PATH):\n",
    "    os.mkdir(TEST_IMG_OUTPUT_PATH)\n",
    "test_images = [ 'test_images/{}'.format(filename) for filename in os.listdir(\"test_images/\") ]\n",
    "test_images.sort()\n",
    "print(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from camera_calibrator import CameraCalibrator, Undistorter\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calibrator = CameraCalibrator(9, 6)\n",
    "\n",
    "calibrator.calibrate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtx, dist = calibrator.get_calibration_data()\n",
    "print(mtx, dist, calibrator.get_shape())\n",
    "undistorter = Undistorter(mtx, dist, calibrator.get_shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#    Calibrator and Undistorter validation\n",
    "#\n",
    "\n",
    "img = cv2.imread(test_images[4])\n",
    "distorted = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "undistorted = undistorter.undistort(distorted)\n",
    "\n",
    "out_shape = [undistorted.shape[0], undistorted.shape[1], 3]\n",
    "output = np.zeros(out_shape)\n",
    "output[:,:,0] = cv2.resize(distorted, (out_shape[1], out_shape[0]))//16\n",
    "output[:,:,2] = undistorted//16\n",
    "plt.figure(figsize=FIGURE_SIZE)\n",
    "plt.imshow(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bgr(img):\n",
    "    \"\"\" A helper for plotting a BGR image with matplotlib \"\"\"\n",
    "    plt.figure(figsize=FIGURE_SIZE)\n",
    "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    \n",
    "def plot_gray(gray):\n",
    "    plt.figure(figsize=FIGURE_SIZE)\n",
    "    plt.imshow(gray, cmap='gray')\n",
    "\n",
    "def plot_roi_on(img, roi):\n",
    "    if len(img.shape) == 2:\n",
    "        output = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
    "    else:\n",
    "        output = img.copy()\n",
    "    roi_color = (255, 0, 255)\n",
    "    thickness = 4\n",
    "    cv2.polylines(output, [roi], True, roi_color, thickness)\n",
    "    return output\n",
    "    \n",
    "def normalize(img):\n",
    "    \"\"\" Expects a grayscale image \"\"\"\n",
    "    minimum = np.min(img)\n",
    "    maximum = np.max(img)\n",
    "    normalized = (((img + minimum) / (maximum - minimum) ) * 255).astype(np.uint8)\n",
    "    return normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_hls_mix(img, frame_size=(1280, 720), save_output=False):\n",
    "    \"\"\" Expects a cv2 mat (in BGR) as input \"\"\"\n",
    "    # The idea is to mix Lum and Sat channels to improve lane lines visibility\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_BGR2HLS)\n",
    "    lum = hls[:,:,1].astype(np.int16)\n",
    "    sat = hls[:,:,2].astype(np.int16)\n",
    "    mix = (lum * 0.5) + (sat * 0.6 )\n",
    "    output = normalize(mix)\n",
    "    if output.shape != frame_size:\n",
    "        output = cv2.resize(output, frame_size)\n",
    "    if save_output :\n",
    "        cv2.imwrite(os.path.join(TEST_IMG_OUTPUT_PATH, \"stage_01.jpg\"), output)\n",
    "    return output\n",
    "\n",
    "def to_lumgrad_sat_mix(img, save_output=False):\n",
    "    \"\"\" Expects a cv2 mat (in BGR) as input \"\"\"\n",
    "    # The idea is to mix Lum and Sat channels to improve lane lines visibility\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_BGR2HLS)\n",
    "    lum = cv2.medianBlur(hls[:,:,1].astype(np.int16), 3)\n",
    "    sat = cv2.medianBlur(hls[:,:,2].astype(np.int16), 3)\n",
    "\n",
    "    #plot_gray(normalize(lum))\n",
    "    lumgrad = normalize(np.absolute(cv2.Sobel(lum, cv2.CV_64F, 1, 0, ksize=5)))*4\n",
    "    #lumgrad = normalize(np.absolute(cv2.Laplacian(lum, cv2.CV_64F)))*4\n",
    "    satgrad = normalize(np.absolute(cv2.Sobel(sat, cv2.CV_64F, 1, 0, ksize=5)))*4\n",
    "    #satgrad = normalize(np.absolute(cv2.Laplacian(sat, cv2.CV_64F)))*4\n",
    "    plot_gray(lumgrad)\n",
    "    plot_gray(satgrad)\n",
    "\n",
    "    mix = (lumgrad) + (satgrad) + (lum//4) + (sat//4)\n",
    "    return mix\n",
    "    \n",
    "def to_high_contrast(img, frame_size=(1280, 720), save_output=False):\n",
    "    \"\"\" Expects a cv2 mat (in BGR) as input \"\"\"\n",
    "    # The idea is to mix Lum and Sat channels to improve lane lines visibility\n",
    "    height, width = img.shape[:2]\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_BGR2HLS)\n",
    "    lum = hls[:,:,1].astype(np.int16)\n",
    "    sat = hls[:,:,2].astype(np.int16)\n",
    "    \n",
    "    lum_thr = 100\n",
    "    min_lum = np.maximum(0, lum - lum_thr)\n",
    "    lum_part = normalize(np.power(min_lum, 2))\n",
    "    \n",
    "    sat_thr = sat.mean()\n",
    "    min_sat = np.maximum(0, sat - sat_thr)\n",
    "    sat_part = np.minimum(255, min_sat + 100)\n",
    "    mix = np.maximum(sat_part, lum_part)\n",
    "    output = np.maximum(0, np.minimum(mix, 255)).astype(np.uint8)\n",
    "    return output\n",
    "\n",
    "def adaptive_contrast(img, frame_size=(1280, 720), save_output=False):\n",
    "    \"\"\" Expects a cv2 mat (in BGR) as input \"\"\"\n",
    "    # The idea is to mix Lum and Sat channels to improve lane lines visibility\n",
    "    height, width = img.shape[:2]\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_BGR2HLS)\n",
    "    lum = hls[:,:,1]\n",
    "    sat = hls[:,:,2]\n",
    "    \n",
    "    hist_roi_top = height//2 + 10\n",
    "    lum_hist = np.histogram(lum[hist_roi_top::16, ::16],8)\n",
    "    lum_thr = lum_hist[1][np.argmax(lum_hist[0])]*0.9\n",
    "    \n",
    "    sat_hist = np.histogram(sat[hist_roi_top::16, ::16],8)\n",
    "    sat_thr = sat_hist[1][np.argmax(sat_hist[0])]*0.9\n",
    "    \n",
    "    min_lum = np.maximum(0, lum.astype(np.int32) - lum_thr)\n",
    "    lum_part = normalize(np.power(min_lum, 2))\n",
    "\n",
    "    min_sat = np.maximum(0, sat.astype(np.int32) - sat_thr)\n",
    "    sat_part = normalize(np.power(min_sat, 1.5))\n",
    "    \n",
    "    mix = np.maximum(sat_part, lum_part)\n",
    "    output = np.maximum(0, np.minimum(mix, 255)).astype(np.uint8)\n",
    "    #plot_gray(min_sat)\n",
    "    return output\n",
    "\n",
    "h_center = 1280//2\n",
    "w_offset = 80\n",
    "top = 460#450\n",
    "bottom = 660\n",
    "left = 100\n",
    "right = 1180\n",
    "MASK_ROI = np.array([[left, bottom],\n",
    "                [h_center - w_offset, top],\n",
    "                [h_center + w_offset, top],\n",
    "                [right, bottom]]\n",
    "               , np.int32)\n",
    "mask = cv2.fillPoly(np.zeros((720,1280), dtype=np.uint8), [MASK_ROI], [255,255,255])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate the HLS pipeline\n",
    "for test_img in test_images[:6]:\n",
    "    img = cv2.resize(cv2.imread(test_img), (1280, 720))\n",
    "    temp = adaptive_contrast(img)\n",
    "    _, st_1 = cv2.threshold(cv2.bitwise_and(temp, mask), 40,255,cv2.THRESH_BINARY)\n",
    "    plot_bgr(img)\n",
    "    plot_gray(st_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Good: gray_input, blur_radius=5, sobel_kernel=17 angle_range=(0.7, 1.3), magnitude_range=(75,255)\n",
    "# TRY; gray_input, blur_radius=3, sobel_kernel=11 angle_range=(0.85, 1.15), magnitude_range=(30,255)\n",
    "ANGLE_RANGE=(0.6, 1.15)\n",
    "def amplify_lane_pixels(gray_input, blur_radius=3, sobel_kernel=15\n",
    "                        , angle_range=ANGLE_RANGE, magnitude_range=(30,255), save_output=False):\n",
    "    \"\"\" Finds and amplifies pixels that are looking as lane line markings\"\"\"\n",
    "    # Either medianBlur or GaussianBlur\n",
    "    # blurred = cv2.medianBlur(gray_input, blur_radius)\n",
    "    blurred = cv2.GaussianBlur(gray_input, (blur_radius, blur_radius), 0)\n",
    "    # Take the absolute value of the x and y gradients\n",
    "    abs_sobelx = np.absolute(cv2.Sobel(blurred, cv2.CV_64F, 1, 0, ksize=sobel_kernel))\n",
    "    abs_sobely = np.absolute(cv2.Sobel(blurred, cv2.CV_64F, 0, 1, ksize=sobel_kernel))\n",
    "    # Calculate the direction of the gradient and select only pixels\n",
    "    # near edges of the matching slope (to the 'angle_range' in radians)\n",
    "    angles = np.arctan2(abs_sobely, abs_sobelx)\n",
    "    (angle_min, angle_max) = angle_range\n",
    "    direction = np.zeros_like(angles)\n",
    "    direction[(angles >= angle_min) & (angles <= angle_max)] = 1\n",
    "    # plot_gray(direction)\n",
    "    # Calculate magnitude of the gradient\n",
    "    mag_raw = normalize(np.sqrt(np.power(abs_sobelx, 2) + np.power(abs_sobely, 2)))\n",
    "    min_magnitude, max_magnitude = magnitude_range;\n",
    "    magnitude = np.zeros_like(blurred)\n",
    "    magnitude[(mag_raw > min_magnitude) & (mag_raw < max_magnitude)] = 1\n",
    "    # plot_gray(magnitude)\n",
    "    # Combining thresholds\n",
    "    combined = np.zeros_like(blurred)\n",
    "    combined[((magnitude == 1) & (direction == 1))] = 1\n",
    "    #combined = magnitude + direction\n",
    "    # plot_gray(combined)\n",
    "    dilate_kernel = np.ones((3,3),np.uint8)\n",
    "    erode_kernel = np.ones((3,3),np.uint8)\n",
    "    #output = cv2.morphologyEx(combined, cv2.MORPH_CLOSE, dilate_kernel)\n",
    "    output = combined\n",
    "    if save_output :\n",
    "        cv2.imwrite(os.path.join(TEST_IMG_OUTPUT_PATH, \"stage_02.jpg\"), normalize(output))\n",
    "    return output\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def amplify_lane_pixels2(gray_input, blur_radius=7, sobel_kernel=13\n",
    "                        , angle_range=(0.8, 1.3), magnitude_range=(10,255), save_output=False):\n",
    "    \"\"\" Finds and amplifies pixels that are looking as lane line markings\"\"\"\n",
    "    # Either medianBlur or GaussianBlur\n",
    "    #blurred = cv2.medianBlur(gray_input, blur_radius)\n",
    "    blurred = cv2.GaussianBlur(gray_input, (blur_radius, blur_radius), 0)\n",
    "    # Take the absolute value of the x and y gradients\n",
    "    abs_sobelx = np.absolute(cv2.Sobel(blurred, cv2.CV_64F, 1, 0, ksize=sobel_kernel))\n",
    "    abs_sobely = np.absolute(cv2.Sobel(blurred, cv2.CV_64F, 0, 1, ksize=sobel_kernel))\n",
    "    # Calculate the direction of the gradient and select only pixels\n",
    "    # near edges of the matching slope (to the 'angle_range' in radians)\n",
    "    angles = np.arctan2(abs_sobely, abs_sobelx)\n",
    "    (angle_min, angle_max) = angle_range\n",
    "    direction = np.zeros_like(angles)\n",
    "    direction[(angles >= angle_min) & (angles <= angle_max)] = 1\n",
    "    # plot_gray(direction)\n",
    "    # Calculate magnitude of the gradient\n",
    "    mag_raw = normalize(np.sqrt(np.power(abs_sobelx, 2) + np.power(abs_sobely, 2)))\n",
    "    min_magnitude, max_magnitude = magnitude_range;\n",
    "    magnitude = np.zeros_like(blurred)\n",
    "    magnitude[(mag_raw > min_magnitude) & (mag_raw < max_magnitude)] = 1\n",
    "    # Combining thresholds\n",
    "    combined = np.zeros_like(blurred)\n",
    "    combined[((magnitude == 1) & (direction == 1))] = 1\n",
    "    #output = combined\n",
    "    dilate_kernel = np.ones((3,3),np.uint8)\n",
    "    output = cv2.morphologyEx(combined, cv2.MORPH_OPEN, dilate_kernel)\n",
    "    if save_output :\n",
    "        cv2.imwrite(os.path.join(TEST_IMG_OUTPUT_PATH, \"stage_02.jpg\"), normalize(output))\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate the HLS pipeline\n",
    "for test_img in test_images[0:-1]:\n",
    "    img = cv2.resize(cv2.imread(test_img), (1280, 720))\n",
    "    st_1 = adaptive_contrast(img)\n",
    "    st_2 = normalize(amplify_lane_pixels(st_1))\n",
    "    plot_bgr(img)\n",
    "    #plot_gray(st_1)\n",
    "    plot_gray(st_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upper_point(lower_point, angle, height, length=250):\n",
    "    ''' Returns the second point at given length and angle from a lower_point '''\n",
    "    ''' The point is always higher (thus the name upper_point) '''\n",
    "    assert(len(lower_point) == 2)\n",
    "    x, y = lower_point\n",
    "    y = height - y\n",
    "    upper_x = x + length * np.cos(angle);\n",
    "    upper_y = height - (y + length * np.sin(angle));\n",
    "\n",
    "    return (int(upper_x), int(upper_y))\n",
    "\n",
    "def visualize_angle_range(img, angle_range=(0.8, 1.2), total_lines=20,\n",
    "                          side_offset=0.4,\n",
    "                          bottom_offset=0.25,\n",
    "                          color=[255,0,255], thickness=2):\n",
    "    ''' Plots a two star-like structures, displaying the slope range '''\n",
    "    height, width = img.shape[:2]\n",
    "    side_margin = int(width * side_offset)\n",
    "    bottom_margin = int(height * bottom_offset)\n",
    "    angles = np.linspace(angle_range[0], angle_range[1], total_lines)\n",
    "    left_origin = (side_margin, height - bottom_margin)\n",
    "    right_origin = (width - side_margin, height - bottom_margin)\n",
    "    left_lines = [[left_origin, upper_point(left_origin, angle, height)] for angle in angles]\n",
    "    right_lines = [[right_origin, upper_point(right_origin, (-1)*angle, height)] for angle in angles]\n",
    "\n",
    "\n",
    "    for line in left_lines:\n",
    "        cv2.line(img, line[0], line[1], color, thickness)\n",
    "    for line in right_lines:\n",
    "        cv2.line(img, line[0], line[1], color, thickness)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate angle range on an image\n",
    "for test_img in test_images[4:5]:\n",
    "    img = cv2.imread(test_img)\n",
    "    plot_bgr(visualize_angle_range(img))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: warp transform here.\n",
    "\n",
    "# TODO: encapsulate the default ROI to a class.\n",
    "''' OLD roi for a cropped undistortion\n",
    "h_center = 600\n",
    "h_offset = 20\n",
    "top = 370\n",
    "bottom = 620 #630\n",
    "left = 100\n",
    "right = 1100'''\n",
    "h_center = 640\n",
    "h_offset = 65\n",
    "top = 460#450\n",
    "bottom = 690\n",
    "left = 200\n",
    "right = 1080\n",
    "CAMERA_ROI = np.array([[left, bottom],\n",
    "                [h_center - h_offset, top],\n",
    "                [h_center + h_offset, top],\n",
    "                [right, bottom]]\n",
    "               , np.int32)\n",
    "\n",
    "birds_top = 0\n",
    "birds_bottom = 720\n",
    "birds_left = left +50\n",
    "birds_right = right -50\n",
    "BIRD_ROI =  np.float32([[birds_left, birds_bottom],\n",
    "                       [birds_left, birds_top],\n",
    "                       [birds_right, birds_top],\n",
    "                       [birds_right, birds_bottom]])\n",
    "\n",
    "class Bird():\n",
    "    def __init__(self, roi, camera_roi=CAMERA_ROI):\n",
    "        # ROIs are expected to be np.float32 arrays of shape (4, 2)\n",
    "        # describing a region starting from the bottom left point clockwise\n",
    "        self.roi = roi\n",
    "        self.camera_roi = camera_roi\n",
    "        self.M = cv2.getPerspectiveTransform(camera_roi, roi)\n",
    "        self.invM = cv2.getPerspectiveTransform(roi, camera_roi)\n",
    "    \n",
    "    def from_above(self, img):\n",
    "        return cv2.warpPerspective(img, self.M, \n",
    "                                   (img.shape[1], img.shape[0]),\n",
    "                                   flags=cv2.INTER_LINEAR)\n",
    "    \n",
    "    def to_road(self, img):\n",
    "        return cv2.warpPerspective(img, self.invM, \n",
    "                                   (img.shape[1], img.shape[0]),\n",
    "                                   flags=cv2.INTER_LINEAR)\n",
    "\n",
    "def to_birdseye(img, roi=CAMERA_ROI):\n",
    "    \"\"\" Expects a trapezoidal ROI to start from the bottom left point \"\"\"\n",
    "    \"\"\" Expects an undistorted input image \"\"\"\n",
    "\n",
    "    M = cv2.getPerspectiveTransform(roi.astype(np.float32), birds_roi)\n",
    "    warped = cv2.warpPerspective(img, M, (img.shape[1], img.shape[0]), flags=cv2.INTER_LINEAR)\n",
    "    return warped\n",
    "\n",
    "bird = Bird(BIRD_ROI, CAMERA_ROI.astype(np.float32))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate the warp transform\n",
    "# https://docs.opencv.org/master/dc/da5/tutorial_py_drawing_functions.html\n",
    "for test_img in test_images[:1]:\n",
    "    #break\n",
    "    img = cv2.resize(cv2.imread(test_img), (1280, 720))\n",
    "    \n",
    "    fpv = undistorter.undistort(img)\n",
    "    fpv_roi = plot_roi_on(fpv, CAMERA_ROI)\n",
    "        \n",
    "    plot_bgr(fpv_roi)\n",
    "    \n",
    "    birds_eye = bird.from_above(fpv)\n",
    "\n",
    "    plot_bgr(birds_eye)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define conversions in x and y from pixels space to meters\n",
    "ym_per_pix = 30/720 # meters per pixel in y dimension\n",
    "xm_per_pix = 3.7/700 # meters per pixel in x dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_poly2(poly, y):\n",
    "    ''' Evaluate a 2-grade polynomial '''\n",
    "    return poly[0]*y*y + poly[1]*y + poly[2]\n",
    "\n",
    "def find_lane_pixels(binary_warped):\n",
    "    # Take a histogram of the bottom half of the image\n",
    "    histogram = np.sum(binary_warped[binary_warped.shape[0]//2:,:], axis=0)\n",
    "    # Create an output image to draw on and visualize the result\n",
    "    out_img = np.dstack((binary_warped, binary_warped, binary_warped))\n",
    "    # Find the peak of the left and right halves of the histogram\n",
    "    # These will be the starting point for the left and right lines\n",
    "    midpoint = np.int(histogram.shape[0]//2)\n",
    "    leftx_base = np.argmax(histogram[:midpoint])\n",
    "    rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "\n",
    "    # HYPERPARAMETERS\n",
    "    # Choose the number of sliding windows\n",
    "    nwindows = 9\n",
    "    # Set the width of the windows +/- margin\n",
    "    margin = 100\n",
    "    # Set minimum number of pixels found to recenter window\n",
    "    minpix = 50\n",
    "\n",
    "    # Set height of windows - based on nwindows above and image shape\n",
    "    window_height = np.int(binary_warped.shape[0]//nwindows)\n",
    "    # Identify the x and y positions of all nonzero pixels in the image\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    # Current positions to be updated later for each window in nwindows\n",
    "    leftx_current = leftx_base\n",
    "    rightx_current = rightx_base\n",
    "\n",
    "    # Create empty lists to receive left and right lane pixel indices\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "\n",
    "    # Step through the windows one by one\n",
    "    for window in range(nwindows):\n",
    "        # Identify window boundaries in x and y (and right and left)\n",
    "        win_y_low = binary_warped.shape[0] - (window+1)*window_height\n",
    "        win_y_high = binary_warped.shape[0] - window*window_height\n",
    "        win_xleft_low = leftx_current - margin \n",
    "        win_xleft_high = leftx_current + margin\n",
    "        win_xright_low = rightx_current - margin\n",
    "        win_xright_high = rightx_current + margin\n",
    "        \n",
    "        # Draw the windows on the visualization image\n",
    "        cv2.rectangle(out_img,(win_xleft_low,win_y_low),\n",
    "        (win_xleft_high,win_y_high),(0,255,0), 2) \n",
    "        cv2.rectangle(out_img,(win_xright_low,win_y_low),\n",
    "        (win_xright_high,win_y_high),(0,255,0), 2) \n",
    "        \n",
    "        ### TO-DO: Identify the nonzero pixels in x and y within the window ###\n",
    "        good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "        (nonzerox >= win_xleft_low) &  (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "        good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "        (nonzerox >= win_xright_low) &  (nonzerox < win_xright_high)).nonzero()[0]\n",
    "        \n",
    "        # Append these indices to the lists\n",
    "        left_lane_inds.append(good_left_inds)\n",
    "        right_lane_inds.append(good_right_inds)\n",
    "        \n",
    "        ### TO-DO: If you found > minpix pixels, recenter next window ###\n",
    "        ### (`right` or `leftx_current`) on their mean position ###\n",
    "        if len(good_left_inds) > minpix:\n",
    "            leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "        if len(good_right_inds) > minpix: \n",
    "            rightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n",
    "\n",
    "    # Concatenate the arrays of indices (previously was a list of lists of pixels)\n",
    "    left_lane_inds = np.concatenate(left_lane_inds)\n",
    "    right_lane_inds = np.concatenate(right_lane_inds)\n",
    "\n",
    "    # Extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "\n",
    "    return leftx, lefty, rightx, righty, out_img\n",
    "\n",
    "def fit_polynomial(binary_warped, xm_per_pix, ym_per_pix):\n",
    "    # Find our lane pixels first\n",
    "    leftx, lefty, rightx, righty, out_img = find_lane_pixels(binary_warped)\n",
    "\n",
    "    ### TO-DO: Fit a second order polynomial to each using `np.polyfit` ###\n",
    "    left_fit = np.polyfit(lefty*ym_per_pix, leftx*xm_per_pix, 2)\n",
    "    right_fit = np.polyfit(righty*ym_per_pix, rightx*xm_per_pix, 2)\n",
    "\n",
    "    return left_fit, right_fit\n",
    "\n",
    "def get_plottable_curves(height, left_fit, right_fit, xm_per_pix, ym_per_pix, steps=20):\n",
    "    ploty = np.linspace(0, height, steps)\n",
    "    left_curve = np.int32(list(zip(\n",
    "        evaluate_poly2(left_fit, ploty * ym_per_pix) / xm_per_pix, ploty)))\n",
    "    right_curve = np.int32(list(zip(\n",
    "        evaluate_poly2(right_fit, ploty * ym_per_pix) / xm_per_pix, ploty)))\n",
    "    return left_curve, right_curve\n",
    "    \n",
    "def plot_lane_curves(lane_img, left_curve, right_curve, color=[0,255,255], thickness=4):\n",
    "    out_img = cv2.polylines(lane_img, [left_curve, right_curve], False, color, thickness)\n",
    "    return out_img\n",
    "\n",
    "def plot_lane_poly_on(lane_img, left_curve, right_curve, color=[100,200,100]):\n",
    "    # Right curve's points must go in the opposite order to maintain a\n",
    "    # polygon's points traversing order.\n",
    "    points = np.append(left_curve, right_curve[::-1], axis=0)\n",
    "    cv2.fillPoly(lane_img, [points], color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LaneLine():\n",
    "    def __init__(self, xm_per_pix, ym_per_pix, img_size=(1280, 720), avg_depth=8):\n",
    "        self.avg_depth = avg_depth\n",
    "        # Poly coefficients. averaged during last N calls\n",
    "        self.avg_fit = None\n",
    "        self.isValid = False\n",
    "        # Lane curvature radius in meters\n",
    "        self.radius_m = 1e3\n",
    "        # Distance in meters of vehicle center from the line\n",
    "        # (assuming the car is centered and the lane width is 3.75 meters)\n",
    "        self.line_base_pos_mm = 3750./2\n",
    "        # x values for detected line pixels\n",
    "        self.allx = None  \n",
    "        # y values for detected line pixels\n",
    "        self.ally = None\n",
    "        self.xm_per_pix = xm_per_pix\n",
    "        self.ym_per_pix = ym_per_pix\n",
    "        self.img_width, self.img_height = img_size\n",
    "        self.lane_h_center_mm = (self.img_width // 2) * self.xm_per_pix * 1000.\n",
    "    \n",
    "    def update(self, poly, x_pixels=None, y_pixels=None):\n",
    "        if x_pixels is not None:\n",
    "            self.x_pixels = x_pixels\n",
    "        if y_pixels is not None:\n",
    "            self.y_pixels = y_pixels\n",
    "        if self.avg_fit is None:\n",
    "            self.avg_fit = poly\n",
    "        else:\n",
    "            # Improvement of a naive averaging: if the diff is huge,\n",
    "            # do a more conservative averaging. \n",
    "            # TODO: probably, not every member is equally important.\n",
    "            diff = np.absolute(self.avg_fit - poly)\n",
    "            # weighted_diff = (diff[0]**2) + np.absolute(diff[1])\n",
    "            weighted_diff = np.absolute(diff[0]) + np.absolute(diff[1]) + np.absolute(diff[2])\n",
    "            dynamic_depth = int(max(weighted_diff, self.avg_depth))\n",
    "            self.avg_fit = (self.avg_fit * (dynamic_depth - 1) + poly) / dynamic_depth\n",
    "        self.line_base_pos_mm = evaluate_poly2(\n",
    "            self.avg_fit, self.img_height * self.ym_per_pix)*1000 - self.lane_h_center_mm\n",
    "        \n",
    "    def get_fit(self):\n",
    "        return self.avg_fit\n",
    "    \n",
    "    @staticmethod\n",
    "    def evaluate_poly2(poly, y):\n",
    "        # Evaluates a 2-grade polynomial\n",
    "        return poly[0]*y*y + poly[1]*y + poly[2]\n",
    "    \n",
    "    @staticmethod\n",
    "    def curvature(polynome, ycoord):\n",
    "        if polynome is None:\n",
    "            return 0.\n",
    "        A, B, C = polynome\n",
    "        numerator = np.power((1 + np.power((2 * A * ycoord + B), 2)), 3/2)\n",
    "        denominator = 2 * np.abs(A)\n",
    "        return numerator / denominator\n",
    "    \n",
    "    def get_curvature(self):\n",
    "        new_curvature = self.curvature(self.avg_fit, self.img_height * ym_per_pix)\n",
    "        self.radius_m = (self.radius_m * (self.avg_depth - 1) + new_curvature) / self.avg_depth\n",
    "        return self.radius_m\n",
    "    \n",
    "    def get_horizontal_offset(self):\n",
    "        return self.line_base_pos_mm\n",
    "    \n",
    "    def reset(self):\n",
    "        self.avg_fit = None\n",
    "        self.isValid = False\n",
    "        self.radius_m = 1e3\n",
    "        self.line_base_pos_mm = 3750./2\n",
    "        self.allx = None  \n",
    "        self.ally = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_circles(img, lcurv, rcurv):\n",
    "    avg_curv = (lcurv + rcurv) / 2\n",
    "    r_color = [0,0,255]\n",
    "    l_color = [255,0,255]\n",
    "    thickness = 15\n",
    "    height, width = img.shape[:2]\n",
    "    h_center = width // 2\n",
    "    left_avg_center = (int(h_center - avg_curv), height)\n",
    "    right_avg_center = (int(h_center + avg_curv), height)\n",
    "    #img, center, radius, color[, thickness\n",
    "    cv2.circle(img, left_avg_center, int(avg_curv), l_color, thickness)\n",
    "    cv2.circle(img, right_avg_center, int(avg_curv), r_color, thickness)\n",
    "    \n",
    "def plot_curvatures_on(img, lcurvature, rcurvature, color=(255, 255, 255), fontScale = 0.6, thickness = 1):\n",
    "    height, width = img.shape[:2]\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX \n",
    "  \n",
    "    # org \n",
    "    origin = (int(width * 0.05), int(height * 0.1)) \n",
    "\n",
    "    # Using cv2.putText() method \n",
    "    return cv2.putText(img, \n",
    "                        \"Radius: left {:5.1f} m, right {:5.1f} m, avg lane {:5.1f} m\"\n",
    "                        .format(lcurvature, rcurvature, (lcurvature + rcurvature) / 2), \n",
    "                        origin, font,  \n",
    "                       fontScale, color, thickness, cv2.LINE_AA)\n",
    "\n",
    "def plot_hcenter_offset_on(img, loffset, roffset, thickness = 1):\n",
    "    offset = loffset + roffset\n",
    "    height, width = img.shape[:2]\n",
    "    green = (0, 255, 0)\n",
    "    red = (0, 0, 255)\n",
    "    origin = (int(width * 0.55), int(height * 0.9)) if (offset > 0) else (int(width * 0.35), int(height * 0.9)) \n",
    "    color = green if (offset > 0) else red\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX \n",
    "    fontScale = 0.6; thickness = 1\n",
    "    return cv2.putText(img, \n",
    "                        \"Offset {} mm\" .format(int(offset)), \n",
    "                        origin, font,  \n",
    "                       fontScale, color, thickness, cv2.LINE_AA)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate lane pixel finding via sliding window\n",
    "for test_img in test_images[5:6]:\n",
    "    img = cv2.resize(cv2.imread(test_img), (1280, 720))\n",
    "    #plot_bgr(plot_roi_on(img, CAMERA_ROI))\n",
    "    hls = adaptive_contrast(img)\n",
    "    fpv = undistorter.undistort(hls)\n",
    "    _, highlight = cv2.threshold(cv2.bitwise_and(fpv, mask), 40,255,cv2.THRESH_BINARY)\n",
    "    birds_eye = bird.from_above(highlight)\n",
    "    lfit, rfit = fit_polynomial(birds_eye, xm_per_pix, ym_per_pix)\n",
    "    lcurve, rcurve = get_plottable_curves(img.shape[0], lfit, rfit, xm_per_pix, ym_per_pix)\n",
    "    found = plot_lane_curves(cv2.cvtColor(birds_eye, cv2.COLOR_GRAY2BGR), lcurve, rcurve)\n",
    "    lcurv = LaneLine.curvature(lfit, 720 * ym_per_pix)\n",
    "    rcurv = LaneLine.curvature(rfit, 720 * ym_per_pix)\n",
    "   \n",
    "    plot_gray(highlight)\n",
    "    \n",
    "    plot_circles(found, lcurv, rcurv)\n",
    "    plot_lane_poly_on(found, lcurve, rcurve)    \n",
    "    plot_bgr(found)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: an Undistorter instance is necessary\n",
    "# xm_per_pix, ym_per_pix, img_size=(1280, 720), avg_depth=8\n",
    "rlane = LaneLine(xm_per_pix, ym_per_pix, avg_depth=8)\n",
    "llane = LaneLine(xm_per_pix, ym_per_pix, avg_depth=8)\n",
    "\n",
    "buffer_frame = None\n",
    "buf_avg = 10\n",
    "\n",
    "def process_frame(frame):\n",
    "    global buffer_frame, buf_avg\n",
    "    bcoeff = 12\n",
    "    \"\"\" Expects an RGB frame as input \"\"\"\n",
    "    height, width, _ = frame.shape\n",
    "    stage_0_sample = adaptive_contrast(frame)\n",
    "    stage_1_sample = normalize(amplify_lane_pixels(stage_0_sample))\n",
    "    #_, stage_1_sample = cv2.threshold(cv2.bitwise_and(stage_0_sample, mask), 40,255,cv2.THRESH_BINARY)\n",
    "    stage_2_sample = bird.from_above(undistorter.undistort(stage_1_sample))\n",
    "    \n",
    "    if buffer_frame is None:\n",
    "        buffer_frame = stage_2_sample.astype(np.int32)\n",
    "    else:\n",
    "        buffer_frame = (buffer_frame * (buf_avg - 1) + stage_2_sample) / buf_avg\n",
    "    filtered_stage2 = np.zeros_like(stage_2_sample)\n",
    "    filtered_stage2[buffer_frame > 55] = 1 # was 40!\n",
    "    filtered_stage2 = cv2.morphologyEx(filtered_stage2, cv2.MORPH_OPEN, np.ones((7,7)))\n",
    "    \n",
    "    lfit, rfit = fit_polynomial(filtered_stage2, #stage_2_sample,\n",
    "                                xm_per_pix, ym_per_pix)\n",
    "    llane.update(lfit); rlane.update(rfit);\n",
    "    \n",
    "    lcurve, rcurve = get_plottable_curves(height, llane.get_fit(), rlane.get_fit()\n",
    "                                          , xm_per_pix, ym_per_pix)\n",
    "    \n",
    "    stage_3_sample = plot_lane_curves(cv2.cvtColor(normalize(filtered_stage2), #stage_2_sample,\n",
    "                                                   cv2.COLOR_GRAY2BGR)\n",
    "                                      , lcurve, rcurve)\n",
    "    plot_circles(stage_3_sample, llane.get_curvature()/xm_per_pix, rlane.get_curvature()/xm_per_pix)\n",
    "    \n",
    "    tile_01 = cv2.cvtColor(cv2.resize(stage_0_sample, (width//2, height//2)), cv2.COLOR_GRAY2BGR)\n",
    "    tile_10 = cv2.cvtColor(cv2.resize(stage_1_sample, (width//2, height//2)), cv2.COLOR_GRAY2BGR)\n",
    "    tile_11 = cv2.resize(stage_3_sample, (width//2, height//2))\n",
    "        \n",
    "    road_poly_from_above = np.zeros_like(frame)\n",
    "    plot_lane_poly_on(road_poly_from_above, lcurve, rcurve)\n",
    "    plot_circles(road_poly_from_above, llane.get_curvature(), rlane.get_curvature())\n",
    "    lane_poly = bird.to_road(road_poly_from_above)\n",
    "    tile_00 = cv2.resize(np.maximum(frame, lane_poly), (width//2, height//2))\n",
    "    \n",
    "    plot_curvatures_on(tile_00, llane.get_curvature(), rlane.get_curvature())\n",
    "\n",
    "    plot_hcenter_offset_on(tile_00, llane.get_horizontal_offset(), rlane.get_horizontal_offset())\n",
    "    \n",
    "    output = np.zeros_like(frame)\n",
    "    output [:height//2, :width//2] = tile_00\n",
    "    output [:height//2, width//2:] = tile_01\n",
    "    output [height//2:, :width//2] = tile_10\n",
    "    output [height//2:, width//2:] = tile_11\n",
    "    return output\n",
    "\n",
    "# Validate lane pixel finding via sliding window\n",
    "for test_img in test_images[5:6]:\n",
    "    img = cv2.resize(cv2.imread(test_img), (1280, 720))\n",
    "    plot_bgr(process_frame(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#input_video = 'harder_challenge_video.mp4'; test_video_output = 'test_video_output/harder_challenge_test_video.mp4'\n",
    "#input_video = 'challenge_video.mp4'; test_video_output = 'test_video_output/challenge_test_video.mp4'\n",
    "input_video = 'project_video.mp4'; test_video_output = 'test_video_output/test_video.mp4'\n",
    "\n",
    "# 37-43 subclip of the main one is the worst\n",
    "clip1 = VideoFileClip(input_video)#.subclip(37,43)#48)\n",
    "#clip1 = VideoFileClip(input_video)\n",
    "white_clip = clip1.fl_image(process_frame)\n",
    "%time white_clip.write_videofile(test_video_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
