{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "%matplotlib inline\n",
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FIGURE_SIZE = (12, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "TEST_IMG_OUTPUT_PATH = \"test_images_output\"\n",
    "\n",
    "if not os.path.isdir(TEST_IMG_OUTPUT_PATH):\n",
    "    os.mkdir(TEST_IMG_OUTPUT_PATH)\n",
    "test_images = [ 'test_images/{}'.format(filename) for filename in os.listdir(\"test_images/\") ]\n",
    "test_images.sort()\n",
    "print(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from camera_calibrator import CameraCalibrator, Undistorter\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calibrator = CameraCalibrator(9, 6)\n",
    "\n",
    "calibrator.calibrate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtx, dist = calibrator.get_calibration_data()\n",
    "print(mtx, dist, calibrator.get_shape())\n",
    "undistorter = Undistorter(mtx, dist, calibrator.get_shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#    Calibrator and Undistorter validation\n",
    "#\n",
    "\n",
    "img = cv2.imread(test_images[4])\n",
    "distorted = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "undistorted = undistorter.undistort(distorted)\n",
    "\n",
    "out_shape = [undistorted.shape[0], undistorted.shape[1], 3]\n",
    "output = np.zeros(out_shape)\n",
    "output[:,:,0] = cv2.resize(distorted, (out_shape[1], out_shape[0]))//16\n",
    "output[:,:,2] = undistorted//16\n",
    "plt.figure(figsize=FIGURE_SIZE)\n",
    "plt.imshow(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bgr(img):\n",
    "    \"\"\" A helper for plotting a BGR image with matplotlib \"\"\"\n",
    "    plt.figure(figsize=FIGURE_SIZE)\n",
    "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    \n",
    "def plot_gray(gray):\n",
    "    plt.figure(figsize=FIGURE_SIZE)\n",
    "    plt.imshow(gray, cmap='gray')\n",
    "\n",
    "def plot_roi_on(img, roi):\n",
    "    if len(img.shape) == 2:\n",
    "        output = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
    "    else:\n",
    "        output = img.copy()\n",
    "    roi_color = (255, 0, 255)\n",
    "    thickness = 4\n",
    "    cv2.polylines(output, [roi], True, roi_color, thickness)\n",
    "    return output\n",
    "    \n",
    "def normalize(img):\n",
    "    \"\"\" Expects a grayscale image \"\"\"\n",
    "    minimum = np.min(img)\n",
    "    maximum = np.max(img)\n",
    "    normalized = (((img + minimum) / (maximum - minimum) ) * 255).astype(np.uint8)\n",
    "    return normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_center = 1280//2\n",
    "w_offset = 70\n",
    "top = 440#460#450\n",
    "bottom = 660\n",
    "left = 150\n",
    "right = 1130\n",
    "MASK_ROI = np.array([[left, bottom],\n",
    "                [h_center - w_offset, top],\n",
    "                [h_center + w_offset, top],\n",
    "                [right, bottom]]\n",
    "               , np.int32)\n",
    "mask = cv2.fillPoly(np.zeros((720,1280), dtype=np.uint8), [MASK_ROI], [255,255,255])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: warp transform here.\n",
    "\n",
    "# TODO: encapsulate the default ROI to a class.\n",
    "''' OLD roi for a cropped undistortion\n",
    "h_center = 600\n",
    "h_offset = 20\n",
    "top = 370\n",
    "bottom = 620 #630\n",
    "left = 100\n",
    "right = 1100'''\n",
    "h_center = 640\n",
    "h_offset = 80\n",
    "top = 470#460#450\n",
    "bottom = 690\n",
    "left = 210\n",
    "right = 1070\n",
    "CAMERA_ROI = np.array([[left, bottom],\n",
    "                [h_center - h_offset, top],\n",
    "                [h_center + h_offset, top],\n",
    "                [right, bottom]]\n",
    "               , np.int32)\n",
    "\n",
    "birds_top = 0\n",
    "birds_bottom = 720\n",
    "birds_left = left +50\n",
    "birds_right = right -50\n",
    "BIRD_ROI =  np.float32([[birds_left, birds_bottom],\n",
    "                       [birds_left, birds_top],\n",
    "                       [birds_right, birds_top],\n",
    "                       [birds_right, birds_bottom]])\n",
    "\n",
    "class Bird():\n",
    "    def __init__(self, roi, camera_roi=CAMERA_ROI):\n",
    "        # ROIs are expected to be np.float32 arrays of shape (4, 2)\n",
    "        # describing a region starting from the bottom left point clockwise\n",
    "        self.roi = roi\n",
    "        self.camera_roi = camera_roi\n",
    "        self.M = cv2.getPerspectiveTransform(camera_roi, roi)\n",
    "        self.invM = cv2.getPerspectiveTransform(roi, camera_roi)\n",
    "    \n",
    "    def from_above(self, img):\n",
    "        return cv2.warpPerspective(img, self.M, \n",
    "                                   (img.shape[1], img.shape[0]),\n",
    "                                   flags=cv2.INTER_LINEAR)\n",
    "    \n",
    "    def to_road(self, img):\n",
    "        return cv2.warpPerspective(img, self.invM, \n",
    "                                   (img.shape[1], img.shape[0]),\n",
    "                                   flags=cv2.INTER_LINEAR)\n",
    "\n",
    "def to_birdseye(img, roi=CAMERA_ROI):\n",
    "    \"\"\" Expects a trapezoidal ROI to start from the bottom left point \"\"\"\n",
    "    \"\"\" Expects an undistorted input image \"\"\"\n",
    "\n",
    "    M = cv2.getPerspectiveTransform(roi.astype(np.float32), birds_roi)\n",
    "    warped = cv2.warpPerspective(img, M, (img.shape[1], img.shape[0]), flags=cv2.INTER_LINEAR)\n",
    "    return warped\n",
    "\n",
    "bird = Bird(BIRD_ROI, CAMERA_ROI.astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate the warp transform\n",
    "# https://docs.opencv.org/master/dc/da5/tutorial_py_drawing_functions.html\n",
    "for test_img in test_images[::3]:\n",
    "    #break\n",
    "    img = cv2.resize(cv2.imread(test_img), (1280, 720))\n",
    "    \n",
    "    fpv = undistorter.undistort(img)\n",
    "    fpv_roi = plot_roi_on(fpv, CAMERA_ROI)\n",
    "        \n",
    "    plot_bgr(fpv_roi)\n",
    "    \n",
    "    birds_eye = bird.from_above(fpv)\n",
    "\n",
    "    plot_bgr(birds_eye)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adaptive_contrast(img, save_output=False):\n",
    "    \"\"\" Expects a cv2 mat (in BGR) as input \"\"\"\n",
    "    # The idea is to mix Lum and Sat channels to improve lane lines visibility\n",
    "    height, width = img.shape[:2]\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_BGR2HLS)\n",
    "    lum = hls[:,:,1]\n",
    "    sat = hls[:,:,2]\n",
    "    \n",
    "    top_significant = height//2 + height//10\n",
    "    \n",
    "    quarter_lum = lum[top_significant::4, ::4]\n",
    "    quarter_sat = sat[top_significant::4, ::4]\n",
    "    \n",
    "    lum_hist = np.histogram(quarter_lum, 12)\n",
    "    lum_thr = lum_hist[1][np.argmax(lum_hist[0])]\n",
    "    \n",
    "    sat_hist = np.histogram(quarter_sat, 8)\n",
    "    sat_thr = sat_hist[1][np.argmax(sat_hist[0])]\n",
    "    \n",
    "    min_lum = np.maximum(0, quarter_lum.astype(np.int32) - lum_thr)\n",
    "    lum_part = normalize(np.minimum(np.power(min_lum, 2), 2550))\n",
    "\n",
    "    min_sat = np.maximum(0, quarter_sat.astype(np.int32) - sat_thr)\n",
    "    sat_part = normalize(np.minimum(np.power(min_sat, 1.5), 600))\n",
    "    \n",
    "    mix = np.maximum(sat_part, lum_part)\n",
    "    mix_hist = np.histogram(mix[::2, ::2],10)\n",
    "    mix_thr = mix_hist[1][np.argmax(mix_hist[0])]\n",
    "    mix = np.maximum(0, mix.astype(np.int32) - mix_thr)\n",
    "    mix = normalize(np.power(mix, 2))\n",
    "    \n",
    "    limited_mix = np.maximum(0, np.minimum(mix, 255)).astype(np.uint8)\n",
    "    output = np.zeros((height, width), dtype=np.uint8)\n",
    "    output[top_significant:, :] = cv2.resize(limited_mix, (width, height - top_significant))\n",
    "    return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subtract_major_tone(img, downsample_rate=2, accuracy=10):\n",
    "    \"\"\" \n",
    "    Finds the nmost popular pixel brightness (major tone) \n",
    "    and then subtracts it from the whole image. This way we shift\n",
    "    brightness curve without adding significant artifacts (as opposed\n",
    "    to a regular thresholding)\n",
    "    \"\"\"\n",
    "    hist = np.histogram(img[::downsample_rate, ::downsample_rate], accuracy)\n",
    "    major = hist[1][np.argmax(hist[0])]\n",
    "    if (major <= 1.0):\n",
    "        # In some cases, the most popular pixel in an image is black\n",
    "        # and so there's nothing to subtract; but still we believe\n",
    "        # the lane markings to be the brightest, and just\n",
    "        # subtract the _second_ most popular pixel brightness.\n",
    "        second_max = np.partition(hist[0], -2)[-2]\n",
    "        second_max_idx = np.where(hist[0] == second_max)[0][0]\n",
    "        major = hist[1][second_max_idx]\n",
    "\n",
    "    return np.maximum(0, img.astype(np.int32) - major)\n",
    "\n",
    "def adaptive_vertical_contrast(img, downsample_rate=2, save_output=False):\n",
    "    \"\"\" Expects a cv2 mat (in BGR) as input \"\"\"\n",
    "    # The idea is to mix Lum and Sat channels to improve lane lines visibility\n",
    "    height, width = img.shape[:2]\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_BGR2HLS)\n",
    "    \n",
    "    # Downsampling significantly increases processing speed\n",
    "    # while introducing only a minor artifacts\n",
    "    G = img[::downsample_rate, ::downsample_rate, 1]\n",
    "    R = img[::downsample_rate, ::downsample_rate, 2]\n",
    "\n",
    "    quarter_lum = hls[::downsample_rate, ::downsample_rate, 1]\n",
    "    quarter_sat = hls[::downsample_rate, ::downsample_rate, 2]\n",
    "    \n",
    "    # Yellow lane marking is the best recognizeabe as a sum of\n",
    "    # yellow brightness and saturation channel\n",
    "    yellow = np.uint8((R.astype(np.uint16) + G) // 2)\n",
    "    filtered_yellow = subtract_major_tone(yellow)\n",
    "\n",
    "    quarter_sat = np.uint8((quarter_sat.astype(np.uint16) + filtered_yellow) // 2)\n",
    "    \n",
    "    #quarter_lum = yellow\n",
    "    \n",
    "    min_lum = subtract_major_tone(subtract_major_tone(quarter_lum))\n",
    "    lum_part = normalize(np.minimum(np.power(min_lum, 2), 2550))\n",
    "\n",
    "    min_sat = subtract_major_tone(subtract_major_tone(quarter_sat))\n",
    "    sat_part = normalize(np.minimum(np.power(min_sat, 2), 2000))\n",
    "\n",
    "    mix = np.uint16(np.maximum(sat_part, lum_part))\n",
    "    mix = normalize(np.power(mix, 2))\n",
    "    \n",
    "    clamped_mix = np.maximum(0, np.minimum(mix, 255)).astype(np.uint8)\n",
    "    output = cv2.resize(clamped_mix, (width, height))\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate the HLS pipeline\n",
    "for test_img in test_images[:1]:\n",
    "    img = cv2.resize(cv2.imread(test_img), (1280, 720))\n",
    "    temp = adaptive_vertical_contrast(bird.from_above(undistorter.undistort(img)))\n",
    "    \n",
    "    plot_bgr(img)\n",
    "    plot_gray(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Good: gray_input, blur_radius=5, sobel_kernel=17 angle_range=(0.7, 1.3), magnitude_range=(75,255)\n",
    "# TRY; gray_input, blur_radius=3, sobel_kernel=11 angle_range=(0.85, 1.15), magnitude_range=(30,255)\n",
    "ANGLE_RANGE=(0.6, 1.15)\n",
    "def amplify_lane_pixels(gray_input, blur_radius=3, sobel_kernel=15\n",
    "                        , angle_range=ANGLE_RANGE, magnitude_range=(30,255), save_output=False):\n",
    "    \"\"\" Finds and amplifies pixels that are looking as lane line markings\"\"\"\n",
    "    # Either medianBlur or GaussianBlur\n",
    "    # blurred = cv2.medianBlur(gray_input, blur_radius)\n",
    "    blurred = cv2.GaussianBlur(gray_input, (blur_radius, blur_radius), 0)\n",
    "    # Take the absolute value of the x and y gradients\n",
    "    abs_sobelx = np.absolute(cv2.Sobel(blurred, cv2.CV_64F, 1, 0, ksize=sobel_kernel))\n",
    "    abs_sobely = np.absolute(cv2.Sobel(blurred, cv2.CV_64F, 0, 1, ksize=sobel_kernel))\n",
    "    # Calculate the direction of the gradient and select only pixels\n",
    "    # near edges of the matching slope (to the 'angle_range' in radians)\n",
    "    angles = np.arctan2(abs_sobely, abs_sobelx)\n",
    "    (angle_min, angle_max) = angle_range\n",
    "    direction = np.zeros_like(angles)\n",
    "    direction[(angles >= angle_min) & (angles <= angle_max)] = 1\n",
    "    # plot_gray(direction)\n",
    "    # Calculate magnitude of the gradient\n",
    "    mag_raw = normalize(np.sqrt(np.power(abs_sobelx, 2) + np.power(abs_sobely, 2)))\n",
    "    min_magnitude, max_magnitude = magnitude_range;\n",
    "    magnitude = np.zeros_like(blurred)\n",
    "    magnitude[(mag_raw > min_magnitude) & (mag_raw < max_magnitude)] = 1\n",
    "    # plot_gray(magnitude)\n",
    "    # Combining thresholds\n",
    "    combined = np.zeros_like(blurred)\n",
    "    combined[((magnitude == 1) & (direction == 1))] = 1\n",
    "    #combined = magnitude + direction\n",
    "    # plot_gray(combined)\n",
    "    dilate_kernel = np.ones((3,3),np.uint8)\n",
    "    erode_kernel = np.ones((3,3),np.uint8)\n",
    "    #output = cv2.morphologyEx(combined, cv2.MORPH_CLOSE, dilate_kernel)\n",
    "    output = combined\n",
    "    if save_output :\n",
    "        cv2.imwrite(os.path.join(TEST_IMG_OUTPUT_PATH, \"stage_02.jpg\"), normalize(output))\n",
    "    return output\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def amplify_lane_pixels2(gray_input, blur_radius=5, sobel_kernel=17\n",
    "                        , angle_range=(0.7, 1.2), magnitude_range=(20,255), save_output=False):\n",
    "    \"\"\" Finds and amplifies pixels that are looking as lane line markings\"\"\"\n",
    "    # Either medianBlur or GaussianBlur\n",
    "    #blurred = cv2.medianBlur(gray_input, blur_radius)\n",
    "    blurred = cv2.GaussianBlur(gray_input, (blur_radius, blur_radius), 0)\n",
    "    # Take the absolute value of the x and y gradients\n",
    "    abs_sobelx = np.absolute(cv2.Sobel(blurred, cv2.CV_64F, 1, 0, ksize=sobel_kernel))\n",
    "    abs_sobely = np.absolute(cv2.Sobel(blurred, cv2.CV_64F, 0, 1, ksize=sobel_kernel))\n",
    "    # Calculate the direction of the gradient and select only pixels\n",
    "    # near edges of the matching slope (to the 'angle_range' in radians)\n",
    "    angles = np.arctan2(abs_sobely, abs_sobelx)\n",
    "    (angle_min, angle_max) = angle_range\n",
    "    #direction = np.zeros_like(angles)\n",
    "    #direction[(angles >= angle_min) & (angles <= angle_max)] = 1\n",
    "    # plot_gray(direction)\n",
    "    # Calculate magnitude of the gradient\n",
    "    mag_raw = normalize(np.sqrt(np.power(abs_sobelx, 2) + np.power(abs_sobely, 2)))\n",
    "    min_magnitude, max_magnitude = magnitude_range;\n",
    "\n",
    "    # Combining thresholds\n",
    "    combined = np.zeros_like(blurred)\n",
    "    combined[(((mag_raw > min_magnitude) & (mag_raw < max_magnitude))\\\n",
    "              & ((angles >= angle_min) & (angles <= angle_max)))] = 255\n",
    "    output = combined\n",
    "    #dilate_kernel = np.ones((3,3),np.uint8)\n",
    "    #output = cv2.morphologyEx(combined, cv2.MORPH_OPEN, dilate_kernel)\n",
    "    if save_output :\n",
    "        cv2.imwrite(os.path.join(TEST_IMG_OUTPUT_PATH, \"stage_02.jpg\"), normalize(output))\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def amplify_vert_lane_pixels(gray_input, blur_radius=5, sobel_kernel=3,\n",
    "                             angle_range=(-0.5, 0.5), magnitude_range=(20,255),\n",
    "                             downsample_rate=4, save_output=False):\n",
    "    \"\"\" Finds and amplifies pixels that are looking as lane line markings\"\"\"\n",
    "    downsample = gray_input[::downsample_rate, ::downsample_rate]\n",
    "\n",
    "    # Take the absolute value of the x and y gradients\n",
    "    abs_sobelx = np.absolute(cv2.Sobel(downsample, cv2.CV_64F, 1, 0, ksize=sobel_kernel))\n",
    "    abs_sobely = np.absolute(cv2.Sobel(downsample, cv2.CV_64F, 0, 1, ksize=sobel_kernel))\n",
    "\n",
    "    # Calculate the direction of the gradient and select only pixels\n",
    "    # near edges of the matching slope (to the 'angle_range' in radians)\n",
    "    angles = np.arctan2(abs_sobely, abs_sobelx)\n",
    "    (angle_min, angle_max) = angle_range\n",
    "\n",
    "    # Calculate magnitude of the gradient\n",
    "    mag_raw = normalize(np.sqrt(np.power(abs_sobelx, 2) + np.power(abs_sobely, 2)))\n",
    "    min_magnitude, max_magnitude = magnitude_range;\n",
    "\n",
    "    # Combining thresholds\n",
    "    combined = np.zeros_like(downsample)\n",
    "    combined[(((mag_raw > min_magnitude) & (mag_raw < max_magnitude))\\\n",
    "              & ((angles >= angle_min) & (angles <= angle_max)))] = 255\n",
    "    output = cv2.resize(normalize(combined), (gray_input.shape[1], gray_input.shape[0]))\n",
    "\n",
    "    if save_output :\n",
    "        cv2.imwrite(os.path.join(TEST_IMG_OUTPUT_PATH, \"stage_02.jpg\"), normalize(output))\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contrast_processing(img):\n",
    "    bird_eye = bird.from_above(undistorter.undistort(img))\n",
    "    contrast = adaptive_vertical_contrast(bird_eye)\n",
    "    #_, st_1 = cv2.threshold(contrast, 15, 255, cv2.THRESH_BINARY)\n",
    "    st_1 = contrast\n",
    "    st_2 = normalize(amplify_vert_lane_pixels(st_1, angle_range=(-0.5, 0.5),\n",
    "                                              magnitude_range=(20,255),\n",
    "                                             sobel_kernel=3))\n",
    "    return cv2.cvtColor(st_2, cv2.COLOR_GRAY2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input_video = 'harder_challenge_video.mp4'; test_video_output = 'test_video_output/contrast_harder_challenge_test_video.mp4'\n",
    "#input_video = 'challenge_video.mp4'; test_video_output = 'test_video_output/contrast_challenge_test_video.mp4'\n",
    "input_video = 'project_video.mp4'; test_video_output = 'test_video_output/contrast_test_video.mp4'\n",
    "\n",
    "# 37-43 subclip of the main one is the worst\n",
    "clip1 = VideoFileClip(input_video).subclip(46,48)#48)\n",
    "#clip1 = VideoFileClip(input_video)\n",
    "white_clip = clip1.fl_image(contrast_processing)\n",
    "%time white_clip.write_videofile(test_video_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Validate the HLS pipeline\n",
    "for test_img in test_images[:1]:\n",
    "    img = cv2.resize(cv2.imread(test_img), (1280, 720))\n",
    "    bird_eye = bird.from_above(undistorter.undistort(img))\n",
    "    contrast = adaptive_vertical_contrast(bird_eye)\n",
    "    #_, st_1 = cv2.threshold(contrast, 15, 255, cv2.THRESH_BINARY)\n",
    "    st_1 = contrast\n",
    "    st_2 = normalize(amplify_vert_lane_pixels(st_1, angle_range=(-0.5, 0.5),\n",
    "                                              magnitude_range=(20,255),\n",
    "                                             sobel_kernel=3))\n",
    "    plot_bgr(img)\n",
    "    plot_gray(contrast)\n",
    "    #plot_gray(st_1)\n",
    "    plot_gray(st_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define conversions in x and y from pixels space to meters\n",
    "ym_per_pix = 30/720 # meters per pixel in y dimension\n",
    "xm_per_pix = 3.7/700 # meters per pixel in x dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_poly2(poly, y):\n",
    "    ''' Evaluate a 2-grade polynomial '''\n",
    "    return poly[0]*y*y + poly[1]*y + poly[2]\n",
    "\n",
    "def get_lane_template_birdeye(shape, lane_width = 60):\n",
    "    width = shape[1]\n",
    "    left_line_desired_position = width * 1 // 4\n",
    "    right_line_desired_position = width * 3 // 4\n",
    "    salted = np.zeros(shape, dtype=np.uint8)\n",
    "    salted[:, left_line_desired_position-lane_width:left_line_desired_position+lane_width] = 255\n",
    "    salted[:, right_line_desired_position-lane_width:right_line_desired_position+lane_width] = 255\n",
    "    return salted\n",
    "\n",
    "def find_lane_pixels(binary_warped):\n",
    "    # Take a histogram of the bottom half of the image\n",
    "    histogram = np.sum(binary_warped[binary_warped.shape[0]//2:,:], axis=0)\n",
    "    # Create an output image to draw on and visualize the result\n",
    "    out_img = np.dstack((binary_warped, binary_warped, binary_warped))\n",
    "    # Find the peak of the left and right halves of the histogram\n",
    "    # These will be the starting point for the left and right lines\n",
    "    midpoint = np.int(histogram.shape[0]//2)\n",
    "    leftx_base = np.argmax(histogram[:midpoint])\n",
    "    rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "\n",
    "    # HYPERPARAMETERS\n",
    "    # Choose the number of sliding windows\n",
    "    nwindows = 9\n",
    "    # Set the width of the windows +/- margin\n",
    "    margin = 100\n",
    "    # Set minimum number of pixels found to recenter window\n",
    "    minpix = 50\n",
    "\n",
    "    # Set height of windows - based on nwindows above and image shape\n",
    "    window_height = np.int(binary_warped.shape[0]//nwindows)\n",
    "    # Identify the x and y positions of all nonzero pixels in the image\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    # Current positions to be updated later for each window in nwindows\n",
    "    leftx_current = leftx_base\n",
    "    rightx_current = rightx_base\n",
    "\n",
    "    # Create empty lists to receive left and right lane pixel indices\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "\n",
    "    # Step through the windows one by one\n",
    "    for window in range(nwindows):\n",
    "        # Identify window boundaries in x and y (and right and left)\n",
    "        win_y_low = binary_warped.shape[0] - (window+1)*window_height\n",
    "        win_y_high = binary_warped.shape[0] - window*window_height\n",
    "        win_xleft_low = leftx_current - margin \n",
    "        win_xleft_high = leftx_current + margin\n",
    "        win_xright_low = rightx_current - margin\n",
    "        win_xright_high = rightx_current + margin\n",
    "        # Draw the windows on the visualization image\n",
    "        cv2.rectangle(out_img,(win_xleft_low,win_y_low),\n",
    "                      (win_xleft_high, win_y_high),(0,255,0), 2) \n",
    "        cv2.rectangle(out_img,(win_xright_low,win_y_low),\n",
    "                      (win_xright_high, win_y_high),(0,255,0), 2) \n",
    "        \n",
    "        ### TO-DO: Identify the nonzero pixels in x and y within the window ###\n",
    "        good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "        (nonzerox >= win_xleft_low) &  (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "        good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "        (nonzerox >= win_xright_low) &  (nonzerox < win_xright_high)).nonzero()[0]\n",
    "        \n",
    "        # Append these indices to the lists\n",
    "        left_lane_inds.append(good_left_inds)\n",
    "        right_lane_inds.append(good_right_inds)\n",
    "        \n",
    "        ### TO-DO: If you found > minpix pixels, recenter next window ###\n",
    "        ### (`right` or `leftx_current`) on their mean position ###\n",
    "        if len(good_left_inds) > minpix:\n",
    "            leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "        if len(good_right_inds) > minpix: \n",
    "            rightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n",
    "\n",
    "    # Concatenate the arrays of indices (previously was a list of lists of pixels)\n",
    "    left_lane_inds = np.concatenate(left_lane_inds)\n",
    "    right_lane_inds = np.concatenate(right_lane_inds)\n",
    "\n",
    "    # Extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "    plot_bgr(out_img)\n",
    "    return leftx, lefty, rightx, righty\n",
    "\n",
    "def take_lane_pixels(binary_warped, lcurve, rcurve, margin=50, downsample_rate=2):\n",
    "    \"\"\"\n",
    "    Expects lcurve and rcurve as array of points.\n",
    "    Vertical stride along the curve must be the same, and must be\n",
    "    equal across both curves.\n",
    "    These points are used as window origins: the point is a [bottom, h_center] of\n",
    "    a window.\n",
    "    Curves must be consistent with an image (e.g. of the same height and compatible width)\n",
    "    Not all of the pixels might be taken into account if the downsample rate is > 1\n",
    "    (this way further polynome fitting becomes faster)\n",
    "    \"\"\"\n",
    "    assert(len(lcurve) > 2 and len(rcurve) > 2)\n",
    "    l_v_stride = lcurve[1][1] - lcurve[0][1]\n",
    "    r_v_stride = rcurve[1][1] - rcurve[0][1]\n",
    "    assert(l_v_stride == r_v_stride)\n",
    "    v_stride = l_v_stride\n",
    "    leftx = []; lefty = []; rightx = []; righty = []\n",
    "    # Identify the x and y positions of all nonzero pixels in the image\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    for point in lcurve:\n",
    "        x, y = point\n",
    "        w_left = x - margin; w_right = x + margin\n",
    "        w_top = y; w_bottom = y + v_stride\n",
    "        window = binary_warped[w_top:w_bottom, w_left:w_right]\n",
    "        w_y_indices, w_x_indices = window.nonzero()\n",
    "        if len(w_x_indices > 0):\n",
    "            leftx.append(w_x_indices + w_left-1)\n",
    "            lefty.append(w_y_indices + w_top-1)\n",
    "        # DEBUG!\n",
    "        binary_warped[y:y+v_stride:2, w_left:w_right:2] = 255\n",
    "    for point in rcurve:\n",
    "        x, y = point\n",
    "        w_left = x - margin; w_right = x + margin\n",
    "        w_top = y; w_bottom = y + v_stride\n",
    "        window = binary_warped[w_top:w_bottom, w_left:w_right]\n",
    "        w_y_indices, w_x_indices = window.nonzero()\n",
    "        if len(w_x_indices > 0):\n",
    "            rightx.append(w_x_indices + w_left-1)\n",
    "            righty.append(w_y_indices + w_top-1)\n",
    "        # DEBUG!\n",
    "        binary_warped[y:y+v_stride:2, w_left:w_right:2] = 255\n",
    "    leftx = np.concatenate(leftx)\n",
    "    lefty = np.concatenate(lefty)\n",
    "    rightx = np.concatenate(rightx)\n",
    "    righty = np.concatenate(righty)\n",
    "    #print(leftx)\n",
    "    return leftx, lefty, rightx, righty\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_tricolor = cv2.imread(\"bird_eye.png\")\n",
    "test_takepixel_img = cv2.cvtColor(image_tricolor, cv2.COLOR_BGR2GRAY)\n",
    "test_takepixel_img.shape\n",
    "\n",
    "lx,ly,rx,ry = find_lane_pixels(test_takepixel_img)\n",
    "lfit, rfit = fit_polynomial(birds_eye, lx, ly, rx, ry, xm_per_pix, ym_per_pix)\n",
    "lcurve, rcurve = get_plottable_curves(img.shape[0], lfit, rfit, xm_per_pix, ym_per_pix)\n",
    "\n",
    "lx2,ly2,rx2,ry2 = take_lane_pixels(test_takepixel_img, lcurve, rcurve)\n",
    "\n",
    "testplot = np.zeros_like(image_tricolor)\n",
    "testplot[ly2, lx2, 0] = 255\n",
    "testplot[:,:,1] = test_takepixel_img\n",
    "testplot[ry2, rx2, 2] = 255\n",
    "\n",
    "\n",
    "plot_bgr(test_takepixel_img)\n",
    "plot_bgr(testplot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_polynomial(binary_warped, leftx, lefty, rightx, righty, xm_per_pix, ym_per_pix):\n",
    "    # Find our lane pixels first\n",
    "    if (len(leftx) == 0 or len(lefty) == 0 or len(rightx) == 0 or len(righty) == 0):\n",
    "        salted = get_lane_template_birdeye(binary_warped.shape)\n",
    "        leftx, lefty, rightx, righty = find_lane_pixels(salted)\n",
    "        \n",
    "    left_fit = np.polyfit(lefty*ym_per_pix, leftx*xm_per_pix, 2)\n",
    "\n",
    "    right_fit = np.polyfit(righty*ym_per_pix, rightx*xm_per_pix, 2)\n",
    "    \n",
    "    return left_fit, right_fit\n",
    "\n",
    "def get_plottable_curves(height, left_fit, right_fit, xm_per_pix, ym_per_pix, steps=20):\n",
    "    ploty = np.linspace(0, height, steps)\n",
    "    left_curve = np.int32(list(zip(\n",
    "        evaluate_poly2(left_fit, ploty * ym_per_pix) / xm_per_pix, ploty)))\n",
    "    right_curve = np.int32(list(zip(\n",
    "        evaluate_poly2(right_fit, ploty * ym_per_pix) / xm_per_pix, ploty)))\n",
    "    return left_curve, right_curve\n",
    "    \n",
    "def plot_lane_curves(lane_img, left_curve, right_curve, thickness=6):\n",
    "    out_img = cv2.polylines(lane_img, [left_curve], False, [0,255,255], thickness)\n",
    "    out_img = cv2.polylines(out_img, [right_curve], False, [255,255,0], thickness)\n",
    "    return out_img\n",
    "\n",
    "def plot_lane_poly_on(lane_img, left_curve, right_curve, color=[100,200,100]):\n",
    "    # Right curve's points must go in the opposite order to maintain a\n",
    "    # polygon's points traversing order.\n",
    "    points = np.append(left_curve, right_curve[::-1], axis=0)\n",
    "    cv2.fillPoly(lane_img, [points], color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LaneLine():\n",
    "    def __init__(self, xm_per_pix, ym_per_pix, img_size=(1280, 720), avg_depth=8,\n",
    "                 max_broken_frames=15, max_valid_diff=2.0, name=\"Unnamed\"):\n",
    "        self.avg_depth = avg_depth\n",
    "        # Poly coefficients. averaged during last N calls\n",
    "        self.avg_fit = None\n",
    "        self.isValid = False\n",
    "        # Lane curvature radius in meters\n",
    "        self.radius_m = 1e3\n",
    "        # Distance in meters of vehicle center from the line\n",
    "        # (assuming the car is centered and the lane width is 3.75 meters)\n",
    "        self.line_base_pos_mm = 3750./2\n",
    "        # x values for detected line pixels\n",
    "        self.allx = None  \n",
    "        # y values for detected line pixels\n",
    "        self.ally = None\n",
    "        self.xm_per_pix = xm_per_pix\n",
    "        self.ym_per_pix = ym_per_pix\n",
    "        self.img_width, self.img_height = img_size\n",
    "        self.lane_h_center_mm = (self.img_width // 2) * self.xm_per_pix * 1000.\n",
    "        self.max_broken_frames = max_broken_frames\n",
    "        self.broken_frames = 0\n",
    "        self.name = name\n",
    "        self.max_valid_diff = max_valid_diff\n",
    "    \n",
    "    def update(self, poly, x_pixels=None, y_pixels=None):\n",
    "        if x_pixels is not None:\n",
    "            self.x_pixels = x_pixels\n",
    "        if y_pixels is not None:\n",
    "            self.y_pixels = y_pixels\n",
    "        if self.avg_fit is None:\n",
    "            self.avg_fit = poly\n",
    "        else:\n",
    "            # Improvement of a naive averaging: if the diff is huge,\n",
    "            # do a more conservative averaging. \n",
    "            # TODO: probably, not every member is equally important.\n",
    "            diff = np.absolute(self.avg_fit - poly)\n",
    "            weighted_diff = np.absolute(diff[0]) + np.absolute(diff[1]) + np.absolute(diff[2])\n",
    "            #weighted_diff = np.absolute(diff[0]) + np.absolute(diff[1]) + np.absolute(diff[2])\n",
    "            #print(\" {} weighted_diff : \".format(self.name), weighted_diff)\n",
    "            if weighted_diff > self.max_valid_diff:\n",
    "                self.broken_frames += 1\n",
    "                if self.broken_frames > self.max_broken_frames:\n",
    "                    self.isValid = False\n",
    "                    print(\"ALARM! LANE {} BROKEN!\".format(self.name))\n",
    "                    self.avg_fit = (self.avg_fit * (self.avg_depth - 1) + poly) / self.avg_depth\n",
    "            else:\n",
    "                self.avg_fit = (self.avg_fit * (self.avg_depth - 1) + poly) / self.avg_depth\n",
    "                self.isValid = True\n",
    "                self.broken_frames = 0\n",
    "            self.line_base_pos_mm = evaluate_poly2(\n",
    "                self.avg_fit, self.img_height * self.ym_per_pix)*1000 - self.lane_h_center_mm\n",
    "        \n",
    "    def get_fit(self):\n",
    "        return self.avg_fit\n",
    "    \n",
    "    @staticmethod\n",
    "    def evaluate_poly2(poly, y):\n",
    "        # Evaluates a 2-grade polynomial\n",
    "        return poly[0]*y*y + poly[1]*y + poly[2]\n",
    "    \n",
    "    @staticmethod\n",
    "    def curvature(polynome, ycoord):\n",
    "        if polynome is None:\n",
    "            return 0.\n",
    "        A, B, C = polynome\n",
    "        numerator = np.power((1 + np.power((2 * A * ycoord + B), 2)), 3/2)\n",
    "        denominator = 2 * np.abs(A)\n",
    "        return numerator / denominator\n",
    "    \n",
    "    def get_curvature(self):\n",
    "        new_curvature = self.curvature(self.avg_fit, self.img_height * ym_per_pix)\n",
    "        self.radius_m = (self.radius_m * (self.avg_depth - 1) + new_curvature) / self.avg_depth\n",
    "        return self.radius_m\n",
    "    \n",
    "    def get_horizontal_offset(self):\n",
    "        return self.line_base_pos_mm\n",
    "    \n",
    "    def reset(self):\n",
    "        self.avg_fit = None\n",
    "        self.isValid = False\n",
    "        self.radius_m = 1e3\n",
    "        self.line_base_pos_mm = 3750./2\n",
    "        self.allx = None  \n",
    "        self.ally = None\n",
    "        self.broken_frames = 0\n",
    "        self.name = \"Unnamed\"\n",
    "        \n",
    "    def is_valid(self):\n",
    "        return self.isValid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_circles(img, lcurv, rcurv):\n",
    "    avg_curv = (lcurv + rcurv) / 2\n",
    "    r_color = [0,0,255]\n",
    "    l_color = [255,0,255]\n",
    "    thickness = 15\n",
    "    height, width = img.shape[:2]\n",
    "    h_center = width // 2\n",
    "    left_avg_center = (int(h_center - avg_curv), height)\n",
    "    right_avg_center = (int(h_center + avg_curv), height)\n",
    "    #img, center, radius, color[, thickness\n",
    "    cv2.circle(img, left_avg_center, int(avg_curv), l_color, thickness)\n",
    "    cv2.circle(img, right_avg_center, int(avg_curv), r_color, thickness)\n",
    "    \n",
    "def plot_curvatures_on(img, lcurvature, rcurvature, color=(255, 255, 255), fontScale = 0.6, thickness = 1):\n",
    "    height, width = img.shape[:2]\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX \n",
    "  \n",
    "    # org \n",
    "    origin = (int(width * 0.05), int(height * 0.1)) \n",
    "\n",
    "    # Using cv2.putText() method \n",
    "    return cv2.putText(img, \n",
    "                        \"Radius: left {:5.1f} m, right {:5.1f} m, avg lane {:5.1f} m\"\n",
    "                        .format(lcurvature, rcurvature, (lcurvature + rcurvature) / 2), \n",
    "                        origin, font,  \n",
    "                       fontScale, color, thickness, cv2.LINE_AA)\n",
    "\n",
    "def plot_hcenter_offset_on(img, loffset, roffset, thickness = 1):\n",
    "    offset = loffset + roffset\n",
    "    height, width = img.shape[:2]\n",
    "    green = (0, 255, 0)\n",
    "    red = (0, 0, 255)\n",
    "    origin = (int(width * 0.55), int(height * 0.9)) if (offset > 0) else (int(width * 0.35), int(height * 0.9)) \n",
    "    color = green if (offset > 0) else red\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX \n",
    "    fontScale = 0.6; thickness = 1\n",
    "    return cv2.putText(img, \n",
    "                        \"Offset {} mm\" .format(int(offset)), \n",
    "                        origin, font,  \n",
    "                       fontScale, color, thickness, cv2.LINE_AA)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate lane pixel finding via sliding window\n",
    "for test_img in test_images[2:3]:\n",
    "    img = cv2.resize(undistorter.undistort(cv2.imread(test_img)), (1280, 720))\n",
    "    #plot_bgr(plot_roi_on(img, CAMERA_ROI))\n",
    "    hls = adaptive_vertical_contrast(bird.from_above(img))\n",
    "    highlight = amplify_vert_lane_pixels(hls)\n",
    "    birds_eye = highlight\n",
    "    lx, ly, rx, ry = find_lane_pixels(birds_eye)\n",
    "    cv2.imwrite(\"bird_eye.png\", birds_eye)\n",
    "    #print(lx[0])\n",
    "    lfit, rfit = fit_polynomial(birds_eye, lx, ly, rx, ry, xm_per_pix, ym_per_pix)\n",
    "    lcurve, rcurve = get_plottable_curves(img.shape[0], lfit, rfit, xm_per_pix, ym_per_pix)\n",
    "    lx, ly, rx, ry = take_lane_pixels(birds_eye, lcurve, rcurve)\n",
    "    #print(lx)\n",
    "    lfit2, rfit2 = fit_polynomial(birds_eye, lx, ly, rx, ry, xm_per_pix, ym_per_pix)\n",
    "    lcurve2, rcurve2 = get_plottable_curves(img.shape[0], lfit2, rfit2, xm_per_pix, ym_per_pix)\n",
    "\n",
    "        \n",
    "    found = plot_lane_curves(cv2.cvtColor(birds_eye, cv2.COLOR_GRAY2BGR), lcurve, rcurve)\n",
    "    found = plot_lane_curves(found, lcurve2, rcurve2)\n",
    "\n",
    "    lcurv = LaneLine.curvature(lfit, 720 * ym_per_pix)\n",
    "    rcurv = LaneLine.curvature(rfit, 720 * ym_per_pix)\n",
    "   \n",
    "    #plot_gray(highlight)\n",
    "    #plot_lane_poly_on(found, lcurve, rcurve)    \n",
    "    plot_bgr(found)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: an Undistorter instance is necessary\n",
    "# with avg 10 lanes work. L8 + Buf32(_20) is ok too.\n",
    "# Avg6 + Buf32(_20) works too.\n",
    "rlane = LaneLine(xm_per_pix, ym_per_pix, avg_depth=4, max_valid_diff=1.0, name=\"Right\")\n",
    "llane = LaneLine(xm_per_pix, ym_per_pix, avg_depth=4, max_valid_diff=1.0, name=\"Left\")\n",
    "\n",
    "buffer_frame = None\n",
    "buf_avg = 20\n",
    "\n",
    "def process_frame(frame):\n",
    "    global buffer_frame, buf_avg\n",
    "    \"\"\" Expects an RGB frame as input \"\"\"\n",
    "    height, width, _ = frame.shape\n",
    "    birds_eye = bird.from_above(undistorter.undistort(frame))\n",
    "    stage_0_sample = adaptive_vertical_contrast(birds_eye)\n",
    "    stage_1_sample = normalize(amplify_vert_lane_pixels(stage_0_sample))\n",
    "    #_, stage_1_sample = cv2.threshold(cv2.bitwise_and(stage_0_sample, mask), 40,255,cv2.THRESH_BINARY)\n",
    "    stage_2_sample = stage_1_sample#bird.from_above(stage_1_sample)\n",
    "    \n",
    "    if buffer_frame is None:\n",
    "        buffer_frame = np.uint32(stage_2_sample)\n",
    "    else:\n",
    "        buffer_frame = (buffer_frame * (buf_avg - 1) + stage_2_sample) / buf_avg\n",
    "\n",
    "    filtered_stage2 = np.zeros_like(stage_2_sample)\n",
    "    filtered_stage2[buffer_frame > 20] = 1 # was 40!\n",
    "    filtered_stage2 = cv2.morphologyEx(filtered_stage2, cv2.MORPH_OPEN, np.ones((5,5)))\n",
    "    \n",
    "    lfit, rfit = fit_polynomial(filtered_stage2,\n",
    "                                xm_per_pix, ym_per_pix)\n",
    "    llane.update(lfit); rlane.update(rfit);\n",
    "    \n",
    "    lcurve, rcurve = get_plottable_curves(height, llane.get_fit(), rlane.get_fit()\n",
    "                                          , xm_per_pix, ym_per_pix)\n",
    "    \n",
    "    stage_3_sample = plot_lane_curves(cv2.cvtColor(normalize(filtered_stage2),\n",
    "                                                   cv2.COLOR_GRAY2BGR)\n",
    "                                      , lcurve, rcurve)\n",
    "    #plot_circles(stage_3_sample, llane.get_curvature()/xm_per_pix, rlane.get_curvature()/xm_per_pix)\n",
    "    \n",
    "    tile_01 = cv2.cvtColor(cv2.resize(stage_0_sample, (width//2, height//2)), cv2.COLOR_GRAY2BGR)\n",
    "    tile_10 = cv2.cvtColor(cv2.resize(stage_1_sample, (width//2, height//2)), cv2.COLOR_GRAY2BGR)\n",
    "    tile_11 = cv2.resize(stage_3_sample, (width//2, height//2))\n",
    "        \n",
    "    road_poly_from_above = np.zeros_like(frame)\n",
    "    poly_color = [100,200,100] if (llane.is_valid() and rlane.is_valid()) else [255,0,0]\n",
    "    plot_lane_poly_on(road_poly_from_above, lcurve, rcurve, color=poly_color)\n",
    "    lane_poly = bird.to_road(road_poly_from_above)\n",
    "    tile_00 = cv2.resize(np.maximum(frame, lane_poly), (width//2, height//2))\n",
    "    \n",
    "    plot_curvatures_on(tile_00, llane.get_curvature(), rlane.get_curvature())\n",
    "\n",
    "    plot_hcenter_offset_on(tile_00, llane.get_horizontal_offset(), rlane.get_horizontal_offset())\n",
    "    \n",
    "    output = np.zeros_like(frame)\n",
    "    output [:height//2, :width//2] = tile_00\n",
    "    output [:height//2, width//2:] = tile_01\n",
    "    output [height//2:, :width//2] = tile_10\n",
    "    output [height//2:, width//2:] = tile_11\n",
    "    return output\n",
    "\n",
    "# Validate lane pixel finding via sliding window\n",
    "#for test_img in test_images[:1]:\n",
    "#    img = cv2.resize(cv2.imread(test_img), (1280, 720))\n",
    "#    plot_bgr(process_frame(img))\n",
    "#    buffer_frame = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#input_video = 'harder_challenge_video.mp4'; test_video_output = 'test_video_output/harder_challenge_test_video.mp4'\n",
    "#input_video = 'challenge_video.mp4'; test_video_output = 'test_video_output/challenge_test_video.mp4'\n",
    "input_video = 'project_video.mp4'; test_video_output = 'test_video_output/test_video.mp4'\n",
    "\n",
    "# 37-43 subclip of the main one is the worst, challenge problem on 3..6\n",
    "clip1 = VideoFileClip(input_video)#.subclip(3,6)#48)\n",
    "#clip1 = VideoFileClip(input_video)\n",
    "white_clip = clip1.fl_image(process_frame)\n",
    "%time white_clip.write_videofile(test_video_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
